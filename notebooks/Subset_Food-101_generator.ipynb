{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobrane dane bezpośrednio ze strony są w formie która może być \"odczytana\" odpowiednio tylko za pomocą datasets.Food101 (split, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito',\n",
       " 'bruschetta',\n",
       " 'caesar_salad',\n",
       " 'cannoli',\n",
       " 'caprese_salad',\n",
       " 'carrot_cake',\n",
       " 'ceviche',\n",
       " 'cheese_plate',\n",
       " 'cheesecake',\n",
       " 'chicken_curry',\n",
       " 'chicken_quesadilla',\n",
       " 'chicken_wings',\n",
       " 'chocolate_cake',\n",
       " 'chocolate_mousse',\n",
       " 'churros',\n",
       " 'clam_chowder',\n",
       " 'club_sandwich',\n",
       " 'crab_cakes',\n",
       " 'creme_brulee',\n",
       " 'croque_madame',\n",
       " 'cup_cakes',\n",
       " 'deviled_eggs',\n",
       " 'donuts',\n",
       " 'dumplings',\n",
       " 'edamame',\n",
       " 'eggs_benedict',\n",
       " 'escargots',\n",
       " 'falafel',\n",
       " 'filet_mignon',\n",
       " 'fish_and_chips',\n",
       " 'foie_gras',\n",
       " 'french_fries',\n",
       " 'french_onion_soup',\n",
       " 'french_toast',\n",
       " 'fried_calamari',\n",
       " 'fried_rice',\n",
       " 'frozen_yogurt',\n",
       " 'garlic_bread',\n",
       " 'gnocchi',\n",
       " 'greek_salad',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'grilled_salmon',\n",
       " 'guacamole',\n",
       " 'gyoza',\n",
       " 'hamburger',\n",
       " 'hot_and_sour_soup',\n",
       " 'hot_dog',\n",
       " 'huevos_rancheros',\n",
       " 'hummus',\n",
       " 'ice_cream',\n",
       " 'lasagna',\n",
       " 'lobster_bisque',\n",
       " 'lobster_roll_sandwich',\n",
       " 'macaroni_and_cheese',\n",
       " 'macarons',\n",
       " 'miso_soup',\n",
       " 'mussels',\n",
       " 'nachos',\n",
       " 'omelette',\n",
       " 'onion_rings',\n",
       " 'oysters',\n",
       " 'pad_thai',\n",
       " 'paella',\n",
       " 'pancakes',\n",
       " 'panna_cotta',\n",
       " 'peking_duck',\n",
       " 'pho',\n",
       " 'pizza',\n",
       " 'pork_chop',\n",
       " 'poutine',\n",
       " 'prime_rib',\n",
       " 'pulled_pork_sandwich',\n",
       " 'ramen',\n",
       " 'ravioli',\n",
       " 'red_velvet_cake',\n",
       " 'risotto',\n",
       " 'samosa',\n",
       " 'sashimi',\n",
       " 'scallops',\n",
       " 'seaweed_salad',\n",
       " 'shrimp_and_grits',\n",
       " 'spaghetti_bolognese',\n",
       " 'spaghetti_carbonara',\n",
       " 'spring_rolls',\n",
       " 'steak',\n",
       " 'strawberry_shortcake',\n",
       " 'sushi',\n",
       " 'tacos',\n",
       " 'takoyaki',\n",
       " 'tiramisu',\n",
       " 'tuna_tartare',\n",
       " 'waffles']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load entire data\n",
    "_ = datasets.Food101(root=Path.cwd().parent / \"Data\", download=True)\n",
    "\n",
    "# images path\n",
    "images_path = Path.cwd().parent / \"Data/food-101/images\"\n",
    "\n",
    "all_data = datasets.ImageFolder(\n",
    "    root=images_path,\n",
    "    transform=transforms.ToTensor()  # This part will be conducted in dataloader.py for data prepared in cells below \n",
    ")\n",
    "\n",
    "all_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT_TO_GET = 0.3\n",
    "N_FOLDS = 5\n",
    "TARGET_CLASSES = [\"apple_pie\", \"beef_tartare\", \"caesar_salad\", \"cannoli\"]  # wybrane klasy\n",
    "SPLITS = {\"train\": 0.7, \"val\": 0.15, \"test\": 0.15} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent / \"Data\"\n",
    "split_str = \"_\".join(f\"{k[:2]}{int(v * 100)}\" for k, v in SPLITS.items())\n",
    "target_dir_name = data_path / f\"food-101_{str(int(AMOUNT_TO_GET*100))}%_{split_str}\"\n",
    "target_dir = Path(target_dir_name)\n",
    "\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save classes to txt inside folder\n",
    "with open(target_dir_name / \"classes.txt\", \"w\") as f:\n",
    "    for name in TARGET_CLASSES:\n",
    "        f.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRZYGOTOWANIE DANYCH - wybierz jeden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Wyciągnięcie podzbioru danych z Food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Data saved in splits under: /home/kamil-solski/Documents/Python/Projekty_py/Food101/Data/food-101_20%_tr70_va15_te15\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Split and copy\n",
    "for class_name in TARGET_CLASSES:\n",
    "    source_class_dir = images_path / class_name\n",
    "    all_images = list(source_class_dir.glob(\"*.jpg\"))\n",
    "    num_to_sample = int(len(all_images) * AMOUNT_TO_GET)\n",
    "\n",
    "    sampled_images = random.sample(all_images, num_to_sample)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(SPLITS[\"train\"] * num_to_sample)\n",
    "    val_end = train_end + int(SPLITS[\"val\"] * num_to_sample)\n",
    "\n",
    "    train_imgs = sampled_images[:train_end]\n",
    "    val_imgs = sampled_images[train_end:val_end]\n",
    "    test_imgs = sampled_images[val_end:]\n",
    "\n",
    "    split_map = {\n",
    "        \"train\": train_imgs,\n",
    "        \"val\": val_imgs,\n",
    "        \"test\": test_imgs\n",
    "    }\n",
    "\n",
    "    # Copy to corresponding split directories\n",
    "    for split_name, split_images in split_map.items():\n",
    "        split_class_dir = target_dir / split_name / class_name\n",
    "        split_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for img_path in split_images:\n",
    "            shutil.copy(img_path, split_class_dir / img_path.name)\n",
    "\n",
    "print(f\"Done! Data saved in splits under: {target_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Wyciągniecie podzbioru danych z Food101 (z K-Fold Cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! 5-fold cross-validation saved to: /home/kamil-solski/Documents/Python/Projekty_py/Food101/Data/food-101_30%_tr70_va15_te15\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# K-fold processing\n",
    "for class_name in TARGET_CLASSES:\n",
    "    source_class_dir = images_path / class_name\n",
    "    all_images = list(source_class_dir.glob(\"*.jpg\"))\n",
    "    num_to_sample = int(len(all_images) * AMOUNT_TO_GET)\n",
    "    sampled_images = random.sample(all_images, num_to_sample)\n",
    "\n",
    "    # Create KFold instance\n",
    "    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Enumerate folds\n",
    "    for fold_idx, (_, test_val_idx) in enumerate(kf.split(sampled_images)):\n",
    "        fold_dir = target_dir / f\"fold{fold_idx}\"\n",
    "\n",
    "        # Determine test/val/train split inside this fold\n",
    "        test_val_images = [sampled_images[i] for i in test_val_idx]\n",
    "\n",
    "        val_split = int(SPLITS[\"val\"] / (SPLITS[\"val\"] + SPLITS[\"test\"]) * len(test_val_images))\n",
    "        val_imgs = test_val_images[:val_split]\n",
    "        test_imgs = test_val_images[val_split:]\n",
    "        train_imgs = [sampled_images[i] for i in range(len(sampled_images)) if i not in test_val_idx]\n",
    "\n",
    "        split_map = {\n",
    "            \"train\": train_imgs,\n",
    "            \"val\": val_imgs,\n",
    "            \"test\": test_imgs\n",
    "        }\n",
    "\n",
    "        # Copy images to foldX/split/class_name/\n",
    "        for split_name, split_images in split_map.items():\n",
    "            split_class_dir = fold_dir / split_name / class_name\n",
    "            split_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for img_path in split_images:\n",
    "                shutil.copy(img_path, split_class_dir / img_path.name)\n",
    "\n",
    "print(f\"Done! {N_FOLDS}-fold cross-validation saved to: {target_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Food101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
